# Azure Speech Service 話者分離デモ

このプロジェクトは、Azure Cognitive Services の Speech Service を使用したリアルタイム音声認識と話者分離（ダイアライゼーション）のデモアプリケーションです。複数の話者が会話している場合でも、それぞれの発言を自動的に区別して表示します。

## 機能

- リアルタイム音声認識
- 話者分離（複数の話者の発言を自動的に区別）
- 多言語対応（日本語、英語、中国語、韓国語）
- 各話者ごとに異なる色で表示
- 設定の永続化（ローカルストレージ）

## 必要条件

- Azure サブスクリプション
- Azure Speech Service リソース
- 最新のWebブラウザ（Chrome、Edge、Firefoxなど）
- マイク（内蔵または外付け）

## セットアップ手順

1. Azure ポータルで Speech Service リソースを作成します
   - [Azure Portal](https://portal.azure.com/) にログイン
   - リソースの作成 > AI + Machine Learning > Speech Service
   - 必要な情報を入力してリソースを作成

2. Speech Service の認証情報を取得
   - 作成したリソースに移動
   - 「リソース管理」セクションの「キーとエンドポイント」をクリック
   - キー1またはキー2とリージョン情報をメモ

3. アプリケーションの実行
   - このリポジトリをクローンまたはダウンロード
   - `src/index.html` をWebブラウザで開く
   - リージョンとサブスクリプションキーを入力
   - 「認識開始」ボタンをクリック

## 使い方

1. リージョンとサブスクリプションキーを入力します
2. 認識言語を選択します
3. 「認識開始」ボタンをクリックして、マイクへのアクセスを許可します
4. 複数の人で会話すると、それぞれの発言が自動的に区別されて表示されます
5. 「認識終了」ボタンをクリックして認識を停止します

## セキュリティについて

- サブスクリプションキーはブラウザのローカルストレージに保存されますが、サーバーには送信されません
- 実際の本番環境では、キーを直接クライアントサイドで使用するのではなく、バックエンドサービスを経由するトークン認証を使用することをお勧めします

## Azure Speech Service について

Azure Speech Service は、音声テキスト変換、テキスト音声変換、音声翻訳などの機能を提供するクラウドベースのAPIです。このデモでは、会話トランスクリプション（Conversation Transcription）機能を使用しています。

詳細については、[Azure Speech Service のドキュメント](https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/overview)をご覧ください。

## ライセンス

MIT ライセンスの下で公開されています。詳細は [LICENSE](LICENSE) ファイルをご覧ください。